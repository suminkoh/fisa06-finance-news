import os
import requests
from bs4 import BeautifulSoup
from openai import OpenAI
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

# OpenAI ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

from urllib.parse import urljoin

from urllib.parse import parse_qs, urlparse

import urllib.parse

def get_bank_news():
    url = "https://www.reuters.com/business/finance/"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        news_data = []
        items = soup.select("a.story-title, a.media-story-card__heading__link")[:10]

        for item in items:
            title = item.get_text(strip=True)
            link = item.get("href")

            if link and link.startswith("/"):
                link = "https://www.reuters.com" + link

            if title and link:
                news_data.append({
                    "title": title,
                    "link": link
                })

        return news_data

    except Exception as e:
        print("Reuters ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ëŸ¬:", e)
        return []



def get_ai_summary(news_list):
    if not news_list: return "ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    titles = [n['title'] for n in news_list]
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
    "role": "user",
    "content": f"""
ë‹¤ìŒì€ ì˜¤ëŠ˜ì˜ ì£¼ìš” ê¸ˆìœµ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ëª©ë¡ì…ë‹ˆë‹¤.

ì´ ë‰´ìŠ¤ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ,
- ì˜¤ëŠ˜ ê¸ˆìœµ ì‹œì¥ì˜ í•µì‹¬ ì´ìŠˆë¥¼ 2~3ì¤„ë¡œ ìš”ì•½í•˜ê³ 
- ì¶”ê°€ë¡œ ë°‘ì— ê·œì¹™ìœ¼ë¡œ íˆ¬ìì ê´€ì ì—ì„œ ì£¼ëª©í•  ë§Œí•œ íë¦„ì„ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

íˆ¬ìì ì£¼ëª© íë¦„ ì •ë¦¬ì‹œì—ëŠ” ì‘ì„± ê·œì¹™:
- ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
1. ì²« ë²ˆì§¸ í•µì‹¬ ì´ìŠˆ ìš”ì•½
2. ë‘ ë²ˆì§¸ í•µì‹¬ ì´ìŠˆ ìš”ì•½
3. ì„¸ ë²ˆì§¸ í•µì‹¬ ì´ìŠˆ ìš”ì•½
- ê° í•­ëª©ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
- ë¶ˆí•„ìš”í•œ ì„¤ëª… ì—†ì´ í•µì‹¬ë§Œ
- ë¬¸ì¥ë§ˆë‹¤ ì†Œì œëª©+í•œ ë¬¸ì¥ ì •ë¦¬ í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ ë§¤ê²¨ì„œ

í—¤ë“œë¼ì¸:
{titles}
"""
}]
    )
    return response.choices[0].message.content

def make_headline_table(news_list):
    lines = []
    for i, news in enumerate(news_list, 1):
        lines.append(f"| {i} | [{news['title']}]({news['link']}) |")
    return "\n".join(lines)

def update_readme():
    # [ì¤‘ìš”] ì—¬ê¸°ì„œ news_listë¥¼ ë¨¼ì € ë§Œë“¤ì–´ì•¼ ì•„ë˜ì—ì„œ ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
    news_list = get_bank_news()
    ai_briefing = get_ai_summary(news_list)
    headline_table = make_headline_table(news_list)
    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    badge_py = "![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)"
    badge_ai = "![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)"
    badge_gh = "![Github Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white)"

    
    readme_content = f"""# ğŸ¦ Bank News AI Analyzer
{badge_py} {badge_ai} {badge_gh}

> **ğŸ’¡ ê³µì§€:** ë³¸ ë¦¬í¬íŠ¸ëŠ” ë§¤ì¼ ì•„ì¹¨ AIê°€ ìµœì‹  ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ìš”ì•½í•˜ì—¬ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

## ğŸ•’ Last Update: `{now}` (KST)

## ğŸ¤– AI ì• ë„ë¦¬ìŠ¤íŠ¸ ì˜¤ëŠ˜ì˜ ë¸Œë¦¬í•‘

{ai_briefing}

## ğŸ“° ì‹¤ì‹œê°„ ì£¼ìš” í—¤ë“œë¼ì¸
| ë²ˆí˜¸ | ë‰´ìŠ¤ ì œëª© (í´ë¦­ ì‹œ ì´ë™) |
| --- | --- |
{headline_table}

Â© {datetime.now()}
"""



    with open("README.md", "w", encoding="utf-8") as file:
        file.write(readme_content)

if __name__ == "__main__":
    update_readme()
